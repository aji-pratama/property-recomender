{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Spark Configuration\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder\\\n",
    "    .master('local')\\\n",
    "    .config('spark.mongodb.input.uri', 'mongodb://127.0.0.1:27017/propertify')\\\n",
    "    .config('spark.mongodb.output.uri', 'mongodb://127.0.0.1:27017/propertify')\\\n",
    "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.11:2.2.1')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = SparkContext.getOrCreate(\"local\")\n",
    "locale = spark._jvm.java.util.Locale\n",
    "locale.setDefault(locale.forLanguageTag(\"en-US\"))\n",
    "\n",
    "property_df = spark.read\\\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "    .option(\"database\", \"finalproject\")\\\n",
    "    .option(\"collection\", \"property\")\\\n",
    "    .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+---------+--------------------+--------------------+\n",
      "|                 _id|                name|   source|                text|                 url|\n",
      "+--------------------+--------------------+---------+--------------------+--------------------+\n",
      "|[5f049bde5516a0f5...|Rumah Dijual Tang...|Rumah.com|Rumah Dijual Tang...|https://www.rumah...|\n",
      "|[5f049bde5516a0f5...|Cluster Minimalis...|Rumah.com|Rumah cluster mod...|https://www.rumah...|\n",
      "|[5f049bde5516a0f5...|     Puri harmoni 9E|Rumah.com|Rumah subsidi ph9...|https://www.rumah...|\n",
      "|[5f049bde5516a0f5...|Rumah Subsidi Mur...|Rumah.com|Rumah Subsidi Mur...|https://www.rumah...|\n",
      "|[5f049bde5516a0f5...|Rumah Dekat Pintu...|Rumah.com|Cluster O2 Posisi...|https://www.rumah...|\n",
      "+--------------------+--------------------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "property_df.printSchema()\n",
    "property_df.show(5)\n",
    "property_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer\n",
    "from pyspark.ml.feature import StopWordsRemover, VectorAssembler\n",
    "from pyspark.ml.feature import Word2Vec, Word2VecModel\n",
    "from pyspark.ml.feature import IDF, HashingTF\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Processing\n",
    "\n",
    "regexTokenizer = RegexTokenizer(gaps = False, pattern = '\\w+', inputCol = 'text', outputCol = 'token')\n",
    "stopWordsRemover = StopWordsRemover(inputCol = 'token', outputCol = 'nostopwrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HashingTF = HashingTF(inputCol=\"nostopwrd\", outputCol=\"rawFeature\" qw  cwkcw  \n",
    "countVectorizer = CountVectorizer(inputCol=\"nostopwrd\", outputCol=\"rawFeature\")\n",
    "iDF = IDF(inputCol=\"rawFeature\", outputCol=\"idf_vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector data pipline\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopWordsRemover, countVectorizer, iDF])\n",
    "pipeline_mdl = pipeline.fit(property_df)\n",
    "property_trf_df = pipeline_mdl.transform(property_df)\n",
    "all_property_vecs = property_trf_df.select('_id', 'idf_vec').rdd.map(lambda x: (x[0], x[1])).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- token: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- nostopwrd: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rawFeature: vector (nullable = true)\n",
      " |-- idf_vec: vector (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                 _id|                name|                text|                 url|             idf_vec|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|[5f049bde5516a0f5...|Rumah Dijual Tang...|Rumah Dijual Tang...|https://www.rumah...|(3803,[0,1,2,3,4,...|\n",
      "|[5f049bde5516a0f5...|Cluster Minimalis...|Rumah cluster mod...|https://www.rumah...|(3803,[0,1,2,3,7,...|\n",
      "|[5f049bde5516a0f5...|     Puri harmoni 9E|Rumah subsidi ph9...|https://www.rumah...|(3803,[0,2,3,4,6,...|\n",
      "|[5f049bde5516a0f5...|Rumah Subsidi Mur...|Rumah Subsidi Mur...|https://www.rumah...|(3803,[0,1,2,3,4,...|\n",
      "|[5f049bde5516a0f5...|Rumah Dekat Pintu...|Cluster O2 Posisi...|https://www.rumah...|(3803,[1,2,3,5,6,...|\n",
      "|[5f049bde5516a0f5...|Bintaro Jaya Sekt...|Rumah Baru di Pur...|https://www.rumah...|(3803,[0,1,2,3,9,...|\n",
      "|[5f049bde5516a0f5...|Termurah! Rumah M...|Termurah! Rumah M...|https://www.rumah...|(3803,[0,1,2,3,4,...|\n",
      "|[5f049bde5516a0f5...|Rumah Subsidi Min...|Rumah Subsidi Min...|https://www.rumah...|(3803,[0,1,2,3,4,...|\n",
      "|[5f049bdf5516a0f5...|Rumah Harga Minim...|Rumah Harga Minim...|https://www.rumah...|(3803,[0,1,2,3,4,...|\n",
      "|[5f049bdf5516a0f5...|Rumah Murah Desai...|Rumah Murah Desai...|https://www.rumah...|(3803,[0,1,2,3,4,...|\n",
      "|[5f049bdf5516a0f5...|Rumah Cluster Cib...|Rumah Cluster Dek...|https://www.rumah...|(3803,[0,2,3,5,6,...|\n",
      "|[5f049bdf5516a0f5...|Rumah Murah 15 Me...|Rumah Murah 15 Me...|https://www.rumah...|(3803,[0,1,2,3,5,...|\n",
      "|[5f049bdf5516a0f5...|Rumah cluster gri...|Luas tanah 77 lua...|https://www.rumah...|(3803,[1,2,5,6,8,...|\n",
      "|[5f049bdf5516a0f5...|Luas tanah 81 m2 ...|Promo vovid\n",
      "     ...|https://www.rumah...|(3803,[1,2,5,6,8,...|\n",
      "|[5f049bdf5516a0f5...|DIJUAL MURAH APAR...|Dijual Apartemen ...|https://www.rumah...|(3803,[1,2,3,5,6,...|\n",
      "|[5f049bdf5516a0f5...|Pengasinan sawang...|Lb/lb: 36/79 siap...|https://www.rumah...|(3803,[1,2,5,6,8,...|\n",
      "|[5f049bdf5516a0f5...|Penawaran terbaik...|Type 36/96 A32\n",
      "  ...|https://www.rumah...|(3803,[1,2,5,6,8,...|\n",
      "|[5f049be05516a0f5...|Limited edition g...|1 lantai siap hun...|https://www.rumah...|(3803,[0,1,2,5,6,...|\n",
      "|[5f049be05516a0f5...|Promo menarik bul...|Type 36/77 griya ...|https://www.rumah...|(3803,[1,2,5,6,8,...|\n",
      "|[5f049be05516a0f5...|Harga terbaik rum...|Type 36/81 griya ...|https://www.rumah...|(3803,[1,2,5,6,8,...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "property_trf_df.printSchema()\n",
    "property_trf_df.select('_id', 'name', 'text', 'url', 'idf_vec').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_property_vecs = property_trf_df.select('_id', 'idf_vec').rdd.map(lambda x: (x[0], x[1])).collect() #change Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_sim(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / np.sqrt(np.dot(vec1, vec1)) / np.sqrt(np.dot(vec2, vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, isnan\n",
    "\n",
    "def get_property_details(in_property):\n",
    "    a = in_property.alias(\"a\")\n",
    "    b = property_df.alias(\"b\")    \n",
    "    return a.join(b, col(\"a.property_id\") == col(\"b._id\"), 'inner').select([col('a.'+xx) for xx in a.columns] + [col('b.name'), col('b.url'), col('b.text'), col('b.source')]).orderBy(\"a.score\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_recomendations(key_words, sim_bus_limit=20):\n",
    "    input_words_df = sc.parallelize([(0, key_words)]).toDF(['_id', 'text'])\n",
    "    input_words_df = pipeline_mdl.transform(input_words_df)\n",
    "    input_key_words_vec = input_words_df.select('idf_vec').collect()[0][0]\n",
    "    sim_property_byword_rdd = sc.parallelize((i[0], float(cosine_sim(input_key_words_vec, i[1]))) for i in all_property_vecs)\n",
    "    property_rdd = sim_property_byword_rdd.sortBy(lambda a: -a[1]).collect()\n",
    "    sim_property_byword_df = spark.createDataFrame(property_rdd) \\\n",
    "         .withColumnRenamed('_1', 'property_id') \\\n",
    "         .withColumnRenamed('_2', 'score')\\\n",
    "         .orderBy(\"score\", ascending=False)\n",
    "    result = sim_property_byword_df.filter(\n",
    "        (col('score')>0) & (~isnan('score'))\n",
    "    ).limit(sim_bus_limit)\n",
    "    return get_property_details(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajipratama/.pyenv/versions/3.7.1/envs/propertify/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+----+---+----+------+\n",
      "|property_id|score|name|url|text|source|\n",
      "+-----------+-----+----+---+----+------+\n",
      "+-----------+-----+----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key_words = 'jaga karsa'\n",
    "\n",
    "keywords_recom_df = get_keywords_recomendations(key_words, 20)\n",
    "keywords_recom_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'property_id': {'oid': '5f03bf83921cfeebe0669027'},\n",
       "  'score': 0.6428073309373508,\n",
       "  'name': 'Rumah dan tanah dijual di Jaga karsa sangat bagus strategis',\n",
       "  'url': 'https://www.rumah.com/listing-properti/dijual-rumah-dan-tanah-dijual-di-jaga-karsa-sangat-bagus-strategis-oleh-irham-thoha-16612979',\n",
       "  'text': 'Tanah dan rumah daerah Jaga Karsa sangat strategis\\n                                    Dijual Tanah dan Bangunan di daerah sangat strategis di Jl. Kahfi Cipedak Jaga Karsa Jakarta selatan deket tol kearah Antasari , Jabodetabek serta bandara Soeta deket kearah Thamrin dan Sudirman ada Bus way dan MRT serta LRT',\n",
       "  'source': 'Rumah.com'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "keywords_recom_df.toJSON().map(lambda j: json.loads(j)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
